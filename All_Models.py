# -*- coding: utf-8 -*-
"""Video Classification_HA4M using 3D CNN+LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hCm4c7A1zsfd8oDXR4pUg9FEyzxo4H22
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import cv2
import random
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping
import einops
import matplotlib.pyplot as plt
import keras
from keras import layers
from PIL import Image
import pickle
import datetime as dt
import keras
from keras import Model
from keras.models import Sequential
from keras.utils import plot_model
from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Reshape, Dropout, LSTM, Input, \
    TimeDistributed, Conv2D, MaxPooling2D, ConvLSTM2D
from keras.applications.vgg16 import VGG16
import matplotlib.pyplot as plt
import numpy as np

seed_constant=27
np.random.seed(seed_constant)
random.seed(seed_constant)
tf.random.set_seed(seed_constant)

# Create a Matplotlib figure and specify the size of the figure.
plt.figure(figsize = (20, 20))

# Get the names of all classes/categories in HA4M.
all_classes_names = os.listdir('/data/amatin/HA4M_Dataset_All/Color')

# Generate a list of 6 random values. The values will be between 0-12,
# where 12 is the total number of class in the dataset.
random_range = random.sample(range(len(all_classes_names)), 6)

# Iterating through all the generated random values.
for counter, random_index in enumerate(random_range, 1):

    # Retrieve a Class Name using the Random Index.
    selected_class_Name = all_classes_names[random_index]

    # Retrieve the list of all the files present in the randomly selected Class Directory.
    files_names_list_in_Class = os.listdir(f'/data/amatin/HA4M_Dataset_All/Color/{selected_class_Name}')

    # Randomly select a action file from the list retrieved from the randomly selected Class Directory.
    selected_file_name = random.choice(files_names_list_in_Class)
    #print(selected_file_name)

    #ok
    x= os.listdir(f'/data/amatin/HA4M_Dataset_All/Color/{selected_class_Name}/{selected_file_name}')
    x.sort()
    #print(x[0])


    dir=r'/data/amatin/HA4M_Dataset_All/Color'
    img_path=dir + '/'+ selected_class_Name+'/'+selected_file_name+'/'+x[1]
    im=Image.open(img_path)

    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    cv2.putText(img, selected_class_Name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

    # Display the frame.
    plt.subplot(2, 3, counter);plt.imshow(img);plt.axis('off')

# Specify the height and width of the frame will be resized in our dataset.
IMAGE_HEIGHT , IMAGE_WIDTH = 112, 112 #64, 64

# Specify the number of frames of a action that will be fed to the model as one sequence.
SEQUENCE_LENGTH = 40 #20

# Specify the directory containing the UCF50 dataset.
DATASET_DIR = "/data/amatin/HA4M_Dataset_All/Color"

# Specify the list containing the names of the classes used for training. Feel free to choose any set of classes.
CLASSES_LIST = ["Action1", "Action2", "Action3", "Action4", "Action5", "Action6", "Action7", "Action8", "Action9", "Action10", "Action11", "Action12"]
#"Action2", "Action3", "Action4", "Action5", "Action6", "Action7", "Action8", "Action9", "Action10", "Action11", "Action12"

def frames_extraction(files_path):
    '''
    This function will extract the required frames from a action files after resizing and normalizing them.
    Args:
        files_path: The path of the action in the disk, whose frames are to be extracted.
    Returns:
        frames_list: A list containing the resized and normalized frames of the action file.
    '''

    # Declare a list to store action frames.
    frames_list = []

    # Get the total number of frames in the action file.
    x = os.listdir(files_path)
    x.sort()
    # print(x[0])
    frames_count = len(x)

    # Iterate through the action file.
    if frames_count >= SEQUENCE_LENGTH:
        # Calculate the the interval after which frames will be added to the list.
        skip_frames_window = max(int(frames_count / SEQUENCE_LENGTH), 1)
        for frame_counter in range(SEQUENCE_LENGTH):
            # Reading the frame from the action file.
            i = int(frame_counter * skip_frames_window)
            img_path = files_path + '/' + x[i]
            # print(img_path)
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            # success,
            frame = img

            # Resize the Frame to fixed height and width.
            resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))

            # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1
            normalized_frame = resized_frame / 255

            # Append the normalized frame into the frames list
            frames_list.append(normalized_frame)
    else:
        for frame_counter in range(frames_count):
            # Reading the frame from the action file.
            img_path = files_path + '/' + x[frame_counter]
            # print(img_path)
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            # success,
            frame = img
            # Resize the Frame to fixed height and width.
            resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))

            # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1
            normalized_frame = resized_frame / 255

            # Append the normalized frame into the frames list
            frames_list.append(normalized_frame)
        if frames_count < SEQUENCE_LENGTH:
            blank_img = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, 3), dtype=np.uint8)
            blank_img = (cv2.cvtColor(blank_img, cv2.COLOR_BGR2RGB))/255

            for frames_count in range(SEQUENCE_LENGTH):
                frames_list.append(blank_img)

    # Return the frames list.

    return frames_list

def create_dataset():
    '''
    This function will extract the data of the selected classes and create the required dataset.
    Returns:
        features:          A list containing the extracted frames of the actions.
        labels:            A list containing the indexes of the classes associated with the actions.
        files_paths: A list containing the paths of the actions in the disk.
    '''

    # Declared Empty Lists to store the features, labels and file path values.
    features = []
    labels = []
    Action_files_paths = []

    # Iterating through all the classes mentioned in the classes list
    for class_index, class_name in enumerate(CLASSES_LIST):

        # Display the name of the class whose data is being extracted.
        print(f'Extracting Data of Class: {class_name}')

        # Get the list of action files present in the specific class name directory.
        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))

        # Iterate through all the files present in the files list.
        for file_name in files_list:

            # Get the complete action path.
            Action_file_path = os.path.join(DATASET_DIR, class_name, file_name)

            #print(Action_file_path)

            # Extract the frames of the action file.
            frames = frames_extraction(Action_file_path)

            # Check if the extracted frames are equal to the SEQUENCE_LENGTH specified above.
            # So ignore the vides having frames less than the SEQUENCE_LENGTH.
            if len(frames) == SEQUENCE_LENGTH:

                # Append the data to their repective lists.
                features.append(frames)
                labels.append(class_index)
                Action_files_paths.append(Action_file_path)

    # Converting the list to numpy arrays
    features = np.asarray(features)
    labels = np.array(labels)

    # Return the frames, class index, and video file path.
    return features, labels, Action_files_paths

# Create the dataset.
features, labels, Action_files_paths = create_dataset()

# Using Keras's to_categorical method to convert labels into one-hot-encoded vectors
one_hot_encoded_labels = to_categorical(labels)

# Split the Data into Train ( 80% ) and Test Set ( 20% ).
features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size = 0.20, shuffle = True, random_state = seed_constant)

print(len(features_train))
print(len(features_test))



no_classes=12
D = 40   #Number of frames.
W = 112  #Frame Width.
H = 112  #Frame Height.
C = 3    #Number of channels.
sample_shape = (D, W, H, C) #Single Video shape.

batch_size1 = 32
no_epochs = 50
learning_rate = 0.0001
validation_split = 0.2
verbosity = 1

#######################    ***    Visualization  ***#########################
def plot_history(history, name):
  """
    Plotting training and validation learning curves.

    Args:
      history: model history with all the metric measures
  """
  fig, (ax1, ax2) = plt.subplots(2)

  fig.set_size_inches(5.5, 9.5)

  # Plot loss
  ax1.set_title('Loss')
  ax1.plot(history.history['loss'], label = 'train')
  ax1.plot(history.history['val_loss'], label = 'test')
  ax1.set_ylabel('Loss')

  # Determine upper bound of y-axis
  max_loss = max(history.history['loss'] + history.history['val_loss'])

  ax1.set_ylim([0, np.ceil(max_loss)])
  ax1.set_xlabel('Epoch')
  ax1.legend(['Train', 'Validation'])

  # Plot accuracy
  ax2.set_title('Accuracy')
  ax2.plot(history.history['accuracy'],  label = 'train')
  ax2.plot(history.history['val_accuracy'], label = 'test')
  ax2.set_ylabel('Accuracy')
  ax2.set_ylim([0, 1])
  ax2.set_xlabel('Epoch')
  ax2.legend(['Train', 'Validation'])
  plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9)
  plt.savefig('/home/amatin/Data/All Modules_v2_simplified/'+name+'_performance.eps')
  #plt.show()
###########################################################################################

def create_convlstm_model():
    '''
    This function will construct the required convlstm model.
    Returns:
        model: It is the required constructed convlstm model.
    '''

    # We will use a Sequential model for model construction
    model = Sequential()

    # Define the Model Architecture.
    ########################################################################################################################

    model.add(ConvLSTM2D(filters=4, kernel_size=(3, 3), activation='tanh', data_format="channels_last",
                         recurrent_dropout=0.2, return_sequences=True, input_shape=(D,W, H, C)))
    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))
    model.add(TimeDistributed(Dropout(0.2)))

    model.add(ConvLSTM2D(filters=8, kernel_size=(3, 3), activation='tanh', data_format="channels_last",
                         recurrent_dropout=0.2, return_sequences=True))
    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))
    model.add(TimeDistributed(Dropout(0.2)))

    model.add(ConvLSTM2D(filters=16, kernel_size=(3, 3), activation='tanh', data_format="channels_last",
                         recurrent_dropout=0.2, return_sequences=True))
    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))
    model.add(TimeDistributed(Dropout(0.2)))

    model.add(ConvLSTM2D(filters=32, kernel_size=(3, 3), activation='tanh', data_format="channels_last",
                         recurrent_dropout=0.2, return_sequences=True))
    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))
    # model.add(TimeDistributed(Dropout(0.2)))
    model.add(Flatten())
    model.add(Dense(no_classes, activation="softmax"))
    model.summary()
    # Return the constructed convlstm model.
    return model

"""**Run convlstm_model**"""

# Construct the required convlstm model.
convlstm_model = create_convlstm_model()

# Display the success message.
print("convlstm_Model Created Successfully!")

# Plot the structure of the contructed model.
plot_model(convlstm_model, to_file='convlstm_model_structure_plot.png', show_shapes=True, show_layer_names=True)

# Create an Instance of Early Stopping Callback
#early_stopping_callback = EarlyStopping(monitor='val_loss', patience=30, mode='min', restore_best_weights=True)

# Compile the model and specify loss function, optimizer and metrics values to the model
convlstm_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=["accuracy"])

# Start training the model.
# convlstm_model_training_history = convlstm_model.fit(x = features_train, y = labels_train, epochs = 120, batch_size = 32,shuffle = True, validation_split = 0.3, callbacks = [early_stopping_callback])

convlstm_model_training_history = convlstm_model.fit(x=features_train, y=labels_train, epochs=no_epochs, batch_size= batch_size1, shuffle=True,
                                             validation_split = validation_split)

'''convlstm_model_training_history = convlstm_model.fit(x=features_train, y=labels_train, epochs=no_epochs, batch_size=batch_size1,
                                                     validation_data=(features_test, labels_test),
                                                     callbacks=[early_stopping_callback])'''

# Evaluate the trained model.
convlstm_model_evaluation_history = convlstm_model.evaluate(features_test, labels_test)

# Get the loss and accuracy from model_evaluation_history.
convlstm_model_evaluation_loss, convlstm_model_evaluation_accuracy = convlstm_model_evaluation_history

# Define the string date format.
# Get the current Date and Time in a DateTime Object.
# Convert the DateTime object to string according to the style mentioned in date_time_format string.
date_time_format = '%Y_%m_%d__%H_%M_%S'
current_date_time_dt = dt.datetime.now()
current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)

# Define a useful name for our model to make it easy for us while navigating through multiple saved models.
convlstm_model_file_name = f'convlstm_model___Date_Time_{current_date_time_string}___Loss_{convlstm_model_evaluation_loss}___Accuracy_{convlstm_model_evaluation_accuracy}.h5'

# Save your Model.
convlstm_model.save(convlstm_model_file_name)


name='convlstm_model_training_history_10'
plot_history(convlstm_model_training_history,name)

print('################################## ** Finished convLSTM Model  ** ###################################################')
################################################################################################


##########################################################################################################

def build_vgg(shape):
    vgg = VGG16(weights="imagenet", input_shape=shape, include_top=False)
    return vgg

def create_LSTM_model():
    vggModel = build_vgg((W,H,C))
    for layer in vggModel.layers[:-1]:
        layer.trainable=False
    model = Sequential()
    input_layer = Input(shape=(D, W, H, C))
    model = TimeDistributed(vggModel)(input_layer)
    model = TimeDistributed(Flatten())(model)
    model = LSTM(128, return_sequences=False)(model)
    model = Dropout(.5)(model)
    output_layer = Dense(no_classes, activation='softmax')(model)
    model = Model(input_layer, output_layer)
    return model

"""**RUN LSTM**"""

# Construct the required LRCN model.
LSTM_model = create_LSTM_model()

LSTM_model.summary()
# Display the success message.
print("LSTM_Model Created Successfully!")

# Plot the structure of the contructed LRCN model.
plot_model(LSTM_model, to_file='LSTM_model_structure_plot.png', show_shapes=True, show_layer_names=True)

# Create an Instance of Early Stopping Callback.
#early_stopping_callback = EarlyStopping(monitor='val_loss', patience=30, mode='min', restore_best_weights=True)

# Compile the model and specify loss function, optimizer and metrics to the model.
LSTM_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=["accuracy"])

# Start training the model.
LSTM_model_training_history = LSTM_model.fit(x=features_train, y=labels_train, epochs=no_epochs, batch_size= batch_size1, shuffle=True,
                                             validation_split = validation_split)
# Evaluate the trained model.
LSTM_model_model_evaluation_history = LSTM_model.evaluate(features_test, labels_test)

# Get the loss and accuracy from model_evaluation_history.
LSTM_model_evaluation_loss, LSTM_model_evaluation_accuracy = LSTM_model_model_evaluation_history

# Define the string date format.
# Get the current Date and Time in a DateTime Object.
# Convert the DateTime object to string according to the style mentioned in date_time_format string.
date_time_format = '%Y_%m_%d__%H_%M_%S'
current_date_time_dt = dt.datetime.now()
current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)

# Define a useful name for our model to make it easy for us while navigating through multiple saved models.
LSTM_model_file_name = f'LSTM_model___Date_Time_{current_date_time_string}___Loss_{LSTM_model_evaluation_loss}___Accuracy_{LSTM_model_evaluation_accuracy}.h5'

# Save the Model.
LSTM_model.save(LSTM_model_file_name)

name='LSTM_model_training_history_10'
plot_history(LSTM_model_training_history,name)

print('################################## ** Finished LSTM Model  ** ###################################################')
#########################################################################################


# Create a 3D CNN to extract features from the data and Random forest for classification
##########################################################################################################
##########################################################################################################
CNN_3D = keras.models.Sequential([
    keras.layers.Conv3D(32, (3, 3, 3), activation='relu', input_shape=(D, W, H, C)),
    keras.layers.MaxPooling3D((2, 2, 2)),
    keras.layers.Conv3D(64, (3, 3, 3), activation='relu'),
    keras.layers.MaxPooling3D((2, 2, 2)),
    keras.layers.Flatten(),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(12, activation='softmax')
])

CNN_3D.summary()

"""**RUN 3D CNN**"""
# Display the success message.
print("CNN_3D Model Created Successfully!")

# Plot the structure of the contructed LRCN model.
plot_model(CNN_3D, to_file='CNN_3D_structure_plot.png', show_shapes=True, show_layer_names=True)

# Create an Instance of Early Stopping Callback.
#early_stopping_callback = EarlyStopping(monitor='val_loss', patience=30, mode='min', restore_best_weights=True)

# Compile the model and specify loss function, optimizer and metrics to the model.
CNN_3D.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=["accuracy"])

# Start training the model.
CNN_3D_model_training_history = CNN_3D.fit(x=features_train, y=labels_train, epochs=no_epochs, batch_size= batch_size1, shuffle=True,
                                             validation_split = validation_split)

# Evaluate the trained model.
CNN_3D_model_evaluation_history = CNN_3D.evaluate(features_test, labels_test)

# Get the loss and accuracy from model_evaluation_history.
CNN_3D_model_evaluation_loss, CNN_3D_model_evaluation_accuracy = CNN_3D_model_evaluation_history

# Define the string date format.
# Get the current Date and Time in a DateTime Object.
# Convert the DateTime object to string according to the style mentioned in date_time_format string.
date_time_format = '%Y_%m_%d__%H_%M_%S'
current_date_time_dt = dt.datetime.now()
current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)

# Define a useful name for our model to make it easy for us while navigating through multiple saved models.
CNN_3D_model_file_name = f'CNN_3D_model___Date_Time_{current_date_time_string}___Loss_{CNN_3D_model_evaluation_loss}___Accuracy_{CNN_3D_model_evaluation_accuracy}.h5'

# Save the Model.
CNN_3D.save(CNN_3D_model_file_name)


name='CNN_3D_model_training_history_10'
plot_history(CNN_3D_model_training_history,name)

print('################################## ** Finished 3D CNN Model  ** ###################################################')
##########################################################################################################
#############################################################################################

# Create a convLSTM to process the features extracted by the CNN
convlstm_3D_CNN_simplified = keras.models.Sequential([

    keras.layers.ConvLSTM2D(filters=32, kernel_size=(3, 3), activation='tanh', data_format="channels_last",
                         recurrent_dropout=0.2, return_sequences=True, input_shape=(D, W, H, C)),
    keras.layers.MaxPooling3D(pool_size=(2, 2, 2), padding='same', data_format='channels_last'),
    keras.layers.TimeDistributed(Dropout(0.2)),
    keras.layers.Conv3D(32, (3, 3, 3), activation='relu'),
    keras.layers.MaxPooling3D((2, 2, 2)),
    keras.layers.TimeDistributed(Dropout(0.2)),
    keras.layers.Flatten(),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(12, activation='softmax')
])

# ** Run Hybrid convlstm_3D_CNN
convlstm_3D_CNN_simplified.summary()

# Optional - For Debugging
plot_model(convlstm_3D_CNN_simplified, to_file = 'convlstm_3D_CNN_simplified_structure_plot.png', show_shapes = True, show_layer_names = True)

#early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)

convlstm_3D_CNN_simplified.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ["accuracy"])

convlstm_3D_CNN_simplified_model_training_history = convlstm_3D_CNN_simplified.fit(x=features_train, y=labels_train, epochs=no_epochs, batch_size= batch_size1, shuffle=True,
                                             validation_split = validation_split)
# Evaluate the trained model.
convlstm_3D_CNN_simplified_evaluation_history = convlstm_3D_CNN_simplified.evaluate(features_test, labels_test)

# Get the loss and accuracy from model_evaluation_history.
convlstm_3D_CNN_simplified_evaluation_loss, convlstm_3D_CNN_simplified_evaluation_accuracy = convlstm_3D_CNN_simplified_evaluation_history

# Define the string date format.
# Get the current Date and Time in a DateTime Object.
# Convert the DateTime object to string according to the style mentioned in date_time_format string.
date_time_format = '%Y_%m_%d__%H_%M_%S'
current_date_time_dt = dt.datetime.now()
current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)

# Define a useful name for our model to make it easy for us while navigating through multiple saved models.
convlstm_3D_CNN_simplified_model_file_name = f'convlstm_3D_CNN_simplified_model___Date_Time_{current_date_time_string}___Loss_{convlstm_3D_CNN_simplified_evaluation_loss}___Accuracy_{convlstm_3D_CNN_simplified_evaluation_accuracy}.h5'

# Save the Model.
convlstm_3D_CNN_simplified.save(convlstm_3D_CNN_simplified_model_file_name)

name='convlstm_3D_CNN_simplified_model_training_history_10'
plot_history(convlstm_3D_CNN_simplified_model_training_history,name)

print('################################## ** Finished convlstm_3D_CNN_simplified Model  ** ###################################################')





'''convlstm_3D_CNN_old'''
# Create a convLSTM to process the features extracted by the CNN

convlstm_3D_CNN_old = keras.models.Sequential([

    keras.layers.ConvLSTM2D(filters=4, kernel_size=(3, 3), activation='tanh', data_format="channels_last",
                         recurrent_dropout=0.2, return_sequences=True, input_shape=(D, W, H, C)),
    keras.layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'),
    keras.layers.TimeDistributed(Dropout(0.2)),

    keras.layers.ConvLSTM2D(filters=8, kernel_size=(3, 3), activation='tanh', data_format="channels_last",
                         recurrent_dropout=0.2, return_sequences=True),
    keras.layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'),
    keras.layers.TimeDistributed(Dropout(0.2)),
    keras.layers.Conv3D(32, (3, 3, 3), activation='relu'),
    keras.layers.MaxPooling3D((2, 2, 2)),
    keras.layers.Conv3D(64, (3, 3, 3), activation='relu'),
    keras.layers.MaxPooling3D((2, 2, 2)),
    keras.layers.Flatten(),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(12, activation='softmax')
])

# ** Run Hybrid convlstm_3D_CNN
convlstm_3D_CNN_old.summary()

# Optional - For Debugging
plot_model(convlstm_3D_CNN_old, to_file = 'convlstm_3D_CNN_old_structure_plot.png', show_shapes = True, show_layer_names = True)

#early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)

convlstm_3D_CNN_old.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ["accuracy"])

convlstm_3D_CNN_old_model_training_history = convlstm_3D_CNN_old.fit(x=features_train, y=labels_train, epochs=no_epochs, batch_size= batch_size1, shuffle=True,
                                             validation_split = validation_split)
# Evaluate the trained model.
convlstm_3D_CNN_old_evaluation_history = convlstm_3D_CNN_old.evaluate(features_test, labels_test)

# Get the loss and accuracy from model_evaluation_history.
convlstm_3D_CNN_old_evaluation_loss, convlstm_3D_CNN_old_evaluation_accuracy = convlstm_3D_CNN_old_evaluation_history

# Define the string date format.
# Get the current Date and Time in a DateTime Object.
# Convert the DateTime object to string according to the style mentioned in date_time_format string.
date_time_format = '%Y_%m_%d__%H_%M_%S'
current_date_time_dt = dt.datetime.now()
current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)

# Define a useful name for our model to make it easy for us while navigating through multiple saved models.
convlstm_3D_CNN_old_model_file_name = f'convlstm_3D_CNN_old_model___Date_Time_{current_date_time_string}___Loss_{convlstm_3D_CNN_old_evaluation_loss}___Accuracy_{convlstm_3D_CNN_old_evaluation_accuracy}.h5'

# Save the Model.
convlstm_3D_CNN_old.save(convlstm_3D_CNN_old_model_file_name)

name='convlstm_3D_CNN_old_model_training_history_10'
plot_history(convlstm_3D_CNN_old_model_training_history,name)

print('################################## ** Finished convlstm_3D_CNN_old Model  ** ###################################################')
######################################################################################
######################################################################################


################################################################################################
################################################################################################
def create_LRCN_model():
    
    # We will use a Sequential model for model construction.
    model = Sequential()
    # Define the Model Architecture.
    ########################################################################################################################

    model.add(TimeDistributed(Conv2D(16, (3, 3), padding='same', activation='relu'),input_shape=(D, W, H, C)))
    model.add(TimeDistributed(MaxPooling2D((4, 4))))
    model.add(TimeDistributed(Dropout(0.25)))

    model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same', activation='relu')))
    model.add(TimeDistributed(MaxPooling2D((4, 4))))
    model.add(TimeDistributed(Dropout(0.25)))

    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same', activation='relu')))
    model.add(TimeDistributed(MaxPooling2D((2, 2))))
    model.add(TimeDistributed(Dropout(0.25)))

    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same', activation='relu')))
    model.add(TimeDistributed(MaxPooling2D((2, 2))))
    # model.add(TimeDistributed(Dropout(0.25)))

    model.add(TimeDistributed(Flatten()))
    model.add(LSTM(32))
    model.add(Dense(no_classes, activation='softmax'))
    # Display the models summary.
    model.summary()
    return model

"""**Run_LRCN**"""
# Construct the required LRCN model.
LRCN_model = create_LRCN_model()

# Display the success message.
print("LRCN_Model Created Successfully!")

# Plot the structure of the contructed LRCN model.
plot_model(LRCN_model, to_file='LRCN_model_structure_plot.png', show_shapes=True, show_layer_names=True)

# Create an Instance of Early Stopping Callback.
#early_stopping_callback = EarlyStopping(monitor='val_loss', patience=30, mode='min', restore_best_weights=True)

# Compile the model and specify loss function, optimizer and metrics to the model.
LRCN_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=["accuracy"])

# Start training the model.
LRCN_model_training_history = LRCN_model.fit(x=features_train, y=labels_train, epochs=no_epochs, batch_size= batch_size1, shuffle=True,
                                             validation_split = validation_split)

# Evaluate the trained model.
LRCN_model_evaluation_history = LRCN_model.evaluate(features_test, labels_test)

# Get the loss and accuracy from model_evaluation_history.
LRCN_model_evaluation_loss, LRCN_model_evaluation_accuracy = LRCN_model_evaluation_history

# Define the string date format.
# Get the current Date and Time in a DateTime Object.
# Convert the DateTime object to string according to the style mentioned in date_time_format string.
date_time_format = '%Y_%m_%d__%H_%M_%S'
current_date_time_dt = dt.datetime.now()
current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)

# Define a useful name for our model to make it easy for us while navigating through multiple saved models.
LRCN_model_file_name = f'LRCN_model___Date_Time_{current_date_time_string}___Loss_{LRCN_model_evaluation_loss}___Accuracy_{LRCN_model_evaluation_accuracy}.h5'

# Save the Model.
LRCN_model.save(LRCN_model_file_name)

name='LRCN_model_training_history_10'
plot_history(LRCN_model_training_history,name)

print('################################## ** Finished LRCN Model ** ###################################################')
###########################################################################################





###########################################################################################

"""**3D CNN +convLSTM---2nd**"""

cnn_convlstm = keras.models.Sequential([
    keras.layers.Conv3D(32, (3, 3, 3), activation='relu', input_shape=(D, W, H, C)),
    keras.layers.MaxPooling3D((2, 2, 2)),
    keras.layers.Conv3D(64, (3, 3, 3), activation='relu'),
    keras.layers.MaxPooling3D((2, 2, 2)),

    keras.layers.ConvLSTM2D(filters=32, kernel_size=(3, 3), activation='tanh', data_format="channels_last",
                         recurrent_dropout=0.2, return_sequences=True),
    keras.layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'),
    #keras.layers.TimeDistributed(Dropout(0.2)),

    keras.layers.ConvLSTM2D(filters=64, kernel_size=(3, 3), activation='tanh', data_format="channels_last",
                         recurrent_dropout=0.2, return_sequences=True),
    keras.layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'),
    #keras.layers.TimeDistributed(Dropout(0.2)),

    keras.layers.Flatten(),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(12, activation='softmax')
    ])

# ***  Run cnn_convlstm model
cnn_convlstm.summary()
# Optional - For Debugging
plot_model(cnn_convlstm, to_file = 'cnn3D_convlstm_structure_plot.png', show_shapes = True, show_layer_names = True)

#early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)

cnn_convlstm.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ["accuracy"])

cnn_convlstm_model_training_history = cnn_convlstm.fit(x=features_train, y=labels_train, epochs=no_epochs, batch_size= batch_size1, shuffle=True,
                                             validation_split = validation_split)
# Evaluate the trained model.
cnn_convlstm_model_evaluation_history = cnn_convlstm.evaluate(features_test, labels_test)

# Get the loss and accuracy from model_evaluation_history.
cnn_convlstm_evaluation_loss, cnn_convlstm_evaluation_accuracy = cnn_convlstm_model_evaluation_history

# Define the string date format.
# Get the current Date and Time in a DateTime Object.
# Convert the DateTime object to string according to the style mentioned in date_time_format string.
date_time_format = '%Y_%m_%d__%H_%M_%S'
current_date_time_dt = dt.datetime.now()
current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)

# Define a useful name for our model to make it easy for us while navigating through multiple saved models.
cnn_convlstm_model_file_name = f'cnn_convlstm_model___Date_Time_{current_date_time_string}___Loss_{cnn_convlstm_evaluation_loss}___Accuracy_{cnn_convlstm_evaluation_accuracy}.h5'

# Save the Model.
cnn_convlstm.save(cnn_convlstm_model_file_name)

name='cnn_convlstm_model_training_history_10'
plot_history(cnn_convlstm_model_training_history,name)
print('################################## ** Finished 3D CNN + convLSTM Model ** ###################################################')



